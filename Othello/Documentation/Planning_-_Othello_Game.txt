*****************************************************2023 Project***************************************************************************
* Thoughts/ Background: Now is never a bad time to go into ML. Specifically, I aim to implement ""Step 5: Create a machine learned A.I. Create database that stores "good move + board patterns". A.I is trained using machine learning and executes movesaccording to the moves it learnt."".
		The key idea is to treat Othello as a kind of ranking problem. The motivation for this isn't academic, and is more for learning how to train ranking models. Because we can.
		
		There seems to be a wide variety of common methods such as minimax (already implemented in 2019 in this project), genetic algorithms and neural networks. (https://repository.lsu.edu/cgi/viewcontent.cgi?article=1766&context=gradschool_theses 2011)
		Other existing literature seems to point at making use of neural networks for deep learning to play othello, such as on using convolutional neural networks (https://arxiv.org/pdf/1711.06583.pdf 2012). 
		None so far seems to talk about making use of gradient boosted decision trees or trying to model this as a ranking problem. There is one in 2017 that talks about making use of regression (https://pats.cs.cf.ac.uk/@archive_file?p=708&n=final&f=1-Final_Report.pdf&SIG=48a08fc35e0169234716d776bec6f534c2e97babbba9edc889d4c99291178a38)
		It appears possible that learning to play Othello can be modelled as both classification and regression type problem. Note that my previous work on this has nothing to do with literature available.

		Similar to how a search engine will rank documents per search query, it seems possible to model the query as a state of the board and the next move ( othello token to be placed)
		It may not exactly be the case as every "query" is dependent on previous "queries", and the output is dependent on the number of turns taken, and how likely one is close to an end game. 
		Certain state may likely lose to a lost game, and might be a challenge to try to model that.


* An option using .NET is Microsoft's ML.NET library. As of this writing, ML.NET latest version is 2.0.0. * Other framework options are LightGBM.
  # Read https://learn.microsoft.com/en-us/dotnet/api/microsoft.ml.treeextensions.fasttree?view=ml-dotnet#microsoft-ml-treeextensions-fasttree(microsoft-ml-rankingcatalog-rankingtrainers-microsoft-ml-trainers-fasttree-fasttreerankingtrainer-options)
		read also : https://learn.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.fasttree.fasttreerankingtrainer?view=ml-dotnet
     Preparation: Download code and put it into Othello Solution - Done.
	 Lift from documentation:
		FastTree is an efficient implementation of the MART gradient boosting algorithm. Gradient boosting is a machine learning technique for regression problems. 
			https://arxiv.org/abs/1505.01866. 
		MART (Multiple Additive Regression Trees) is an implementation of the gradient tree boosting methods for predictive data mining (regression and classification).
			https://en.wikipedia.org/wiki/Gradient_boosting
			Or better explained in: https://jerryfriedman.su.domains/r-mart/tutorial/tutorial.pdf
		It builds each regression tree in a step-wise fashion, using a predefined loss function to measure the error for each step and corrects for it in the next. 
		MART learns an ensemble of regression trees, which is a decision tree with scalar values in its leaves. 
		A decision (or regression) tree is a binary tree-like flow chart, where at each interior node one decides which of the two child nodes to continue to based on one of the feature values from the input. 
		At each leaf node, a value is returned. In the interior nodes, the decision is based on the test x <= v where x is the value of the feature in the input sample and v is one of the possible values of this feature. 
		The functions that can be produced by a regression tree are all the piece-wise constant functions. https://en.wikipedia.org/wiki/Piecewise

		So this prediction model is actually an ensemble of weaker prediction models. 
		In regression problems, boosting builds a series of such trees in a step-wise fashion and then selects the optimal tree using an arbitrary differentiable loss function.

		The ensemble of trees is produced by computing, in each step, a regression tree that approximates the gradient of the loss function, and adding it to the previous tree with coefficients that minimize the loss of the new tree. 
.
		The output of the ensemble produced by MART on a given instance is the sum of the tree outputs. 
		In case of a ranking problem, the instances are ordered by the output value of the ensemble. 
		Note that In case of a regression problem, the output is the predicted value of the function. Note also that the output of the ensemble produced by MART on a given instance is the sum of the tree outputs. 
		The only difference is how we make use of the output.

		The relationship to LambdaMART is not written: https://towardsdatascience.com/learning-to-rank-a-complete-guide-to-ranking-using-machine-learning-4c9688d370d4


		A data point in training is composed of labels, group id and features. 
			Features: y_ = f(x_) , weights to x is essentially features, like a vector (See n-tuples below as thoughts for features)
			Group ID: It partitions the dataset for each query and document pairs. In the world of Othello, my thoughts are to have the same group ID for the same player. 
				In query-document ranking problems, grouping is used for the model to learn relative importance of different features from different users. So a different game is played by a different player with different decision on moves.
				For this particular phase of the project, there aren't multiple players, so it might better to use the same group ID (same player).
				https://towardsdatascience.com/how-to-implement-learning-to-rank-model-using-python-569cd9c49b08
			Label: A score, possibly an indication of a good move (higher scores mean higher chances to win). Maybe initial label can be making use of the heuristics output from min-max algorithm. Later can try giving more knowledge like the end-game states after n moves.


  # Execution steps:
     Step 1. Read and try .NET ML tutorials on ranking.
			
	 Step 2. Modify Othello code to generate TokenState and NextToken Pairs. 
			TokenState refers to tuples of Othello token coordinates that are already on the board where each n-tuple is (gameID, x,y, tokentype: back or white or empty, turn)
			NextToken is a n-tuple (x,y, tokentype: black or white, turn)
	 Step 2.5 Consider the weighted objective function to minimize opponent pair counts, maximize own pair counts, and final game win, i.e. m_1 * min (opponent) + m_2 * max (own) * m_3 (maximize final own tokens)
			Evaluation can be NDCG based. Supported easily by the framework.
	 Step 3. Modify Othello code to store these tuples, perhaps in NoSQL DB. Why? Why not just files. Easier querying?
	 Step 4. Generate training pairs from A.I - player plays. Maybe a dozen play should do.
	 Step 5. Generate training pairs from A.I - A.I plays
	 Step 6. Integrate ML Ranked A.I. into A.I code as part of strategy pattern. Should be as simple as adding a routine.
	 Step 7. Change UI to support ML Ranked A.I. as a target A.I player. Store all outcomes in DB.

 


*****************************************************2019 Project***************************************************************************

* OthelloServerless: uses AWS services, mainly Lambda to support mulitple instances of A.I games for multiple players, and DynamoDB to store game states.

* Prerequisites
	 # Install AWS SDK for .NET
	 # Install AWS Tookit for Visual Studio

	 #Understand how AWS serverless applications work under the hood
	     # Read https://aws.amazon.com/blogs/developer/aws-serverless-applications-in-visual-studio/
		 # Set up IAM Users and get credentials
		  * https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/getting-your-credentials.html
 
		 # One-time on AWS side: Apply policies with permissions, in particular lambda full access, dynamoDB full access using the default policies. And the following applied on specific resources.
						(applied to "Resource": "arn:aws:iam::*:user/${aws:username}")
						"iam:GetUser", 
						"iam:CreateAccessKey", 
						"iam:ListAccessKeys", 

						("Resource": "*")
						"iam:CreateAccessKey"
						"iam:DeleteAccessKey",
						"iam:GetAccessKeyLastUsed",
						"iam:GetUser",
						"iam:ListAccessKeys",
						"iam:UpdateAccessKey",
						"iam:GetRole",
						"iam:CreateRole",
						"iam:DeleteRole",
						"iam:AttachRolePolicy",
						"iam:DetachRolePolicy"
						"cloudformation:ListStacks",
						"cloudformation:CreateStack",
						"cloudformation:UpdateStack",
						"cloudformation:DeleteStack",
						"cloudformation:CreateChangeSet",
						"cloudformation:DescribeChangeSet",
						"cloudformation:ExecuteChangeSet",
						"cloudformation:DescribeStacks",
						"cloudformation:DescribeStackEvents",
						"apigateway:*"

		# Deploy by publishing to AWS using Visual Studio context menu under serverless project

	# Use tool like Postman (Windows App) to issue HTTP requests. For exact request definitions, read the Cloudformation serverless.template.
	# Debug using AWS Serverless tests. They can be used to debug line by line through remote debugging
	# Use tools like API Gateway Tests to see what is wrong..for e.g. "internal error" can be caused by, e.g. writing logs when lambda only allows readonly.



*****************************************************2013 Project***************************************************************************

Planning - Othello Game

Features
-1 Player versus 1 Player
-1 Player versus A.I.
-Save and Load
-Undo and Redo
-Game engine A.I module
-client GUI


Timeline: (2013)
2013/12/16 - basic design complete
12/17 - basic 1 versus 1 complete. Moves verified until end game. basic tests complete.  need more tests. SaveLoad complete.
12/18 - Undo and Redo. 
12/19 - plan for A.I
12/20 - plan for A.I
12/21 - 22 : break
12/23 - WPF
12/24 - A.I
12/25 - A.I
12/26 - break
12/27 - break
12/28 - break
12/29 - 12/3 (TBD, other studies)


Implementation

		-notes
			-should build and test debug and release modes
			-32bit and 64bit builds and test

		-classes
			-OthelloState: Keeps all information in a single game state. [Serializable]
				(Serializable: HashID	ScoreW	ScoreB	Turn	ChildIDs)
				HashID - unique and persistent per state for quick fetching from stores and keeping child relationships
				ScoreW
				ScoreB
				Turn
				ChildIDs - links to other states
				BoardData

			-OthelloBoard : keep all board information optimized at a bit level. Use 16 bytes to present 8x8board

			-OthelloToken: control a Othello bit with a coordinate. Move can inherit Token.
				CreateToken (x,y, Player)
				EvaluateMove(OthelloStates,x,y,Player)
				GetAllowedMoves(OthelloStates)

			-OthelloPlayer (abstract)
				PlayerScore
				-OthelloAI (type of Player)
					GetMoveScore(OthelloMove, OthelloState, int Depth)
					GetRankedMoves(OthelloMove, OthelloState)
					GetBestMove(int difficulty, OthelloState)

			-OthelloGame: Keeps all information about a single round of Game
				PlayerW
				PlayerB
				CurrentOthelloState
				PastMovesCollection
				MakeMove(OthelloPlayer, OthelloMove, out Next OthelloState)
				CreateNewGame
				IsEndGame
				SaveGame
				LoadGame

			-OthelloAI: Controls the A.I for producing a move given a board state
				GetMoves
					MinMax
					AlphaBeta
				GetNextState


			-OthelloDataGen : Pre-generation for AI search
				StatesCollection
				LoadStates
				SaveStates
				GenerateStates
				PreCalculateStatesScores
				SearchState(ID)

			-Configurability : Saving and Loading of AI tuning files (2014/09/21)
				Saving and Loading of AI Configuration (alpha beta pruning paramters, turns, level, play difficulty), maybe TSV
				Via OthelloGame instead of OthelloAI, as AI config depends on turn and difficulty level

Test Project : Othello Tests
	Speed up verification considerably in later stages.
	Express has no unit test projects. Use NUnit.


Test Notes 
	Make it possible to ingest char based matrix for any board situation.
	Make it possible to ingest move array. For quickly executing moves.
	(5,4)w, (5,3)b, (3,2)w...

A.I notes
	Step 1: Create a basic A.I that does search for all moves in a single state node to get the highest score move. 
	Step 2: Create a richer A.I that does search for all moves in a single state node to get the highest score adjusted by heuristics (move(x1,y1) can be more biased than move (x2, y2) even if they have similar score.
	Step 3: Create a smarter A.I that does brute force search for all moves in future states to get the highest score move for a given state root node.
	Step 4: Create a super smart A.I that does search to look for end games in future states, to prune down the number of searches (discard moves that loses)
	Step 5: Create a machine learned A.I. Create database that stores "good move + board patterns". A.I is trained using machine learning and executes movesaccording to the moves it learnt.

	Step 6: Combine machine learned A.I and brute force search. Discard paths using machine learning.







Game File(Binary)
HashID	ScoreW	ScoreB	Turn	ChildIDs	BoardData

Debug File(Text)
HashID,ScoreW,ScoreB,Turn,ChildIDs	
BoardData
xxxxxxxx	xxxxxxxx
xxxxxxxx        xxxxxxxx
xxxxxxxx        xxxxxxxx
xxxwbxxx        xxxwbxxx
xxwwwwxx        xxxbwxxx
xxxxbxxx        xxxxxxxx
xxxxxxxx        xxxxxxxx
xxxxxxxx        xxxxxxxx

On File, move and state management for A.I can be below. Hash ID can be used as Key to bring down data size. 
Boarddata may be necssary to calculate A.I score, but can be deleted after score calculation to bring down data size.

Move(x,y,player)	HashID1	HashID2
Move(x,y,player)	HashID2	HashID3
Move(x,y,player)	HashID3	HashID4

HashID	AIScore	BoardData



General Notes:
		-Othello should have much less moves per state as not all squares are usable.
		-each state should have ID, score and childs IDs
		-IDs can be hashed using positions of all white and back moves.
		-don't need to search every possible move on memory.
		-can keep states on disk.
		-black and white. 2 possible combinations to start. are these same, but just reflections at the origin? If so they are symmetric, just search for a equivalent move by transforming at the origin.
		-how do we calculate scores? Number of BW from POV of B if A.I is B? How does score affect if look ahead included? Certain key moves may be labeled as ideal, which has score?
			-adding all Bs and Ws over multiple states or the final state at depth=x
		-how do we make the game not too difficult?
		-turns can tell end of game
		-use Trace.Writeline for debugging
		-Binary BoardData : 2bits per coordinate and 8 x 8 = 128bits + bitlength encoding or other kind of compression
		-turns and currentplayer should belong to game state
		-A.I may decouple information within game states used for game management (as A.I does not need all the information)
		-A.I need states and also moves for searching best moves



	GUI - client of A.I module
		-debug using a console stub with simple game loop
		-2nd using WPF with graphics and animation - Shell in progress
		-Debug: Load State

2018 Thoughts:
		-New Features:
			-Network Play
				-Added the idea of observers in the game (further simplify OthelloPlayer to a OthelloPerson, that the observer can inherit from also)
				-matching online players

		-Leveraging Machine Learning: design a ML model to learn and predict good moves from past moves. 
			-looks like a multiclass classification problem (classify moves into good, bad, or so so moves)
				-this means techniques will be Naive Bayes, Support Vector Machines, Decision Trees, Neural Network
					- Features look like heuristics for targeting scoring by traditional means (e.g. bad moves, othello pivots, vectorization of othello board: black and white, number of turns, ratio of black vs white)
					- data collection: 
						- through human to human playing, and storing each move as pairs (player 1 vs. player 2)
						- through human to machine playing, and storing each move as pairs (human player vs machine)

			- Read Paper for further techniques: (Learning to Player Othello with Deep Neural Networks, by Pawel Liskowski, et al)https://arxiv.org/pdf/1711.06583.pdf
		-Btw, also think of how to apply this to other game creation techniques
